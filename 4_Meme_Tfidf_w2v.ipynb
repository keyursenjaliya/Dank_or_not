{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meme_Tfidf-w2v.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0tztVLVsEba",
        "outputId": "6ad7443d-ead9-4e05-ffcf-ec3b5a859f1e"
      },
      "source": [
        "!wget --header=\"Host: doc-0o-7c-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Cookie: AUTH_gbsevnc13krov7rjgq2cj0s062jqolpo=06568700698331676125|1634615700000|klej5cj5jrhqi9vkvioj16q2bmde14in\" --header=\"Connection: keep-alive\" \"https://doc-0o-7c-docs.googleusercontent.com/docs/securesc/ths62md7879q0rdb5g663rm4c96q2241/sr1phqn2ct71pa1m2jr75p8755ogd8g1/1634615700000/00484516897554883881/06568700698331676125/1pGd5tLwA30M7wkbJKdXHaae9tYVDICJ_?e=download&authuser=0\" -c -O 'glove_vectors'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-19 03:56:43--  https://doc-0o-7c-docs.googleusercontent.com/docs/securesc/ths62md7879q0rdb5g663rm4c96q2241/sr1phqn2ct71pa1m2jr75p8755ogd8g1/1634615700000/00484516897554883881/06568700698331676125/1pGd5tLwA30M7wkbJKdXHaae9tYVDICJ_?e=download&authuser=0\n",
            "Resolving doc-0o-7c-docs.googleusercontent.com (doc-0o-7c-docs.googleusercontent.com)... 172.217.204.132, 2607:f8b0:400c:c15::84\n",
            "Connecting to doc-0o-7c-docs.googleusercontent.com (doc-0o-7c-docs.googleusercontent.com)|172.217.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 127506004 (122M) [application/octet-stream]\n",
            "Saving to: ‘glove_vectors’\n",
            "\n",
            "glove_vectors       100%[===================>] 121.60M  97.7MB/s    in 1.2s    \n",
            "\n",
            "2021-10-19 03:56:45 (97.7 MB/s) - ‘glove_vectors’ saved [127506004/127506004]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co0E1fo9evXf"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfM6E_zeemvY",
        "outputId": "770c6648-b310-45bf-8e98-5f36faf3a0c5"
      },
      "source": [
        "import scipy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import zeros\n",
        "import nltk\n",
        "import pickle\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tqdm import tqdm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.metrics  import f1_score,roc_auc_score\n",
        "import warnings\n",
        "nltk.download('vader_lexicon')\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRF3RrLge1_2"
      },
      "source": [
        "#read train and validation data\n",
        "train_data=pd.read_csv('/content/drive/MyDrive/Meme/data/train_data.csv')\n",
        "validation_data=pd.read_csv(\"/content/drive/MyDrive/Meme/data/validation_data.csv\")\n",
        "test_data=pd.read_csv('/content/drive/MyDrive/Meme/data/test_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUYwr6k-fARk"
      },
      "source": [
        "#fill thumbnail.width missing values\n",
        "mean_width=train_data['thumbnail.width'].mean()\n",
        "train_data['thumbnail.width'].fillna(value=mean_width,inplace=True)\n",
        "validation_data['thumbnail.width'].fillna(value=mean_width,inplace=True)\n",
        "test_data['thumbnail.width'].fillna(value=mean_width,inplace=True)\n",
        "\n",
        "# fill  thumbnail.height missing values\n",
        "mean_height=train_data['thumbnail.height'].mean()\n",
        "train_data['thumbnail.height'].fillna(value=mean_height,inplace=True)\n",
        "validation_data['thumbnail.height'].fillna(value=mean_height,inplace=True)\n",
        "test_data['thumbnail.height'].fillna(value=mean_height,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAM52EDMfCBa"
      },
      "source": [
        "#calculate area of image\n",
        "train_data['area']=train_data['thumbnail.height']*train_data['thumbnail.width']\n",
        "validation_data['area']=validation_data['thumbnail.height']*validation_data['thumbnail.width']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OISNYAGHfZ38"
      },
      "source": [
        "#define sentiment scores on text\n",
        "def sentiment_scores(data):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    neg=[]\n",
        "    pos=[]\n",
        "    neu=[]\n",
        "    comp=[]\n",
        "    for sentence in data['text'].values: \n",
        "        sentence_sentiment_score = sid.polarity_scores(sentence)\n",
        "        comp.append(sentence_sentiment_score['compound'])\n",
        "        neg.append(sentence_sentiment_score['neg'])\n",
        "        pos.append(sentence_sentiment_score['pos'])\n",
        "        neu.append(sentence_sentiment_score['neu'])\n",
        "    return comp,neg,pos,neu\n",
        "\n",
        "# Train data  sentiment_scores\n",
        "train_comp,train_neg,train_pos,train_neu=sentiment_scores(train_data)\n",
        "train_data['com']=train_comp\n",
        "train_data['neg']=train_neg\n",
        "train_data['pos']=train_pos\n",
        "train_data['neu']=train_neu\n",
        "\n",
        "#validation data sentiment_scores\n",
        "validation_comp,validation_neg,validation_pos,validation_neu=sentiment_scores(validation_data)\n",
        "validation_data['com']=validation_comp\n",
        "validation_data['neg']=validation_neg\n",
        "validation_data['pos']=validation_pos\n",
        "validation_data['neu']=validation_neu\n",
        "\n",
        "# test data sentiment_scores\n",
        "test_comp,test_neg,test_pos,test_neu=sentiment_scores(test_data)\n",
        "test_data['com']=test_comp\n",
        "test_data['neg']=test_neg\n",
        "test_data['pos']=test_pos\n",
        "test_data['neu']=test_neu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10cKuChMK1L7"
      },
      "source": [
        "Read Image features file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "NSpU7lsPfbjB",
        "outputId": "356004b9-a594-4ca6-e53d-053ec8c79961"
      },
      "source": [
        "train_image_features=pd.read_csv('/content/drive/MyDrive/Meme/data/train_hsv_data.csv')\n",
        "train_image_features['id']=train_image_features['id'].apply(lambda x:x.split(\".\")[0])\n",
        "train_image_features.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>avg_red</th>\n",
              "      <th>avg_green</th>\n",
              "      <th>avg_blue</th>\n",
              "      <th>avg_h</th>\n",
              "      <th>avg_s</th>\n",
              "      <th>avg_v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fkzefu</td>\n",
              "      <td>239.172259</td>\n",
              "      <td>238.365883</td>\n",
              "      <td>238.055094</td>\n",
              "      <td>6.113741</td>\n",
              "      <td>2.055231</td>\n",
              "      <td>239.278907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fkz38w</td>\n",
              "      <td>167.921128</td>\n",
              "      <td>154.234400</td>\n",
              "      <td>146.326260</td>\n",
              "      <td>39.118095</td>\n",
              "      <td>52.000453</td>\n",
              "      <td>169.767484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fkz4wb</td>\n",
              "      <td>67.998585</td>\n",
              "      <td>80.056550</td>\n",
              "      <td>78.199143</td>\n",
              "      <td>35.447353</td>\n",
              "      <td>33.416639</td>\n",
              "      <td>81.083201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fkywwv</td>\n",
              "      <td>70.633591</td>\n",
              "      <td>68.253622</td>\n",
              "      <td>65.874174</td>\n",
              "      <td>79.060371</td>\n",
              "      <td>98.429703</td>\n",
              "      <td>81.938204</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id     avg_red   avg_green    avg_blue      avg_h      avg_s       avg_v\n",
              "0  fkzefu  239.172259  238.365883  238.055094   6.113741   2.055231  239.278907\n",
              "1  fkz38w  167.921128  154.234400  146.326260  39.118095  52.000453  169.767484\n",
              "2  fkz4wb   67.998585   80.056550   78.199143  35.447353  33.416639   81.083201\n",
              "3  fkywwv   70.633591   68.253622   65.874174  79.060371  98.429703   81.938204"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "ToH9Bl0-pf7o",
        "outputId": "29a42aa2-6d2f-4164-c770-454df300e6ec"
      },
      "source": [
        "validation_image_features=pd.read_csv('/content/drive/MyDrive/Meme/data/validation_hsv_data.csv')\n",
        "validation_image_features['id']=validation_image_features['id'].apply(lambda x:x.split(\".\")[0])\n",
        "validation_image_features.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>avg_red</th>\n",
              "      <th>avg_green</th>\n",
              "      <th>avg_blue</th>\n",
              "      <th>avg_h</th>\n",
              "      <th>avg_s</th>\n",
              "      <th>avg_v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fi8zos</td>\n",
              "      <td>105.825954</td>\n",
              "      <td>95.935978</td>\n",
              "      <td>84.807401</td>\n",
              "      <td>18.997557</td>\n",
              "      <td>52.505151</td>\n",
              "      <td>105.987770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fie2qx</td>\n",
              "      <td>116.319292</td>\n",
              "      <td>112.056747</td>\n",
              "      <td>103.298224</td>\n",
              "      <td>14.058189</td>\n",
              "      <td>43.652817</td>\n",
              "      <td>116.648814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fidedo</td>\n",
              "      <td>167.300836</td>\n",
              "      <td>165.844258</td>\n",
              "      <td>167.075575</td>\n",
              "      <td>39.674466</td>\n",
              "      <td>20.069788</td>\n",
              "      <td>170.325628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fipe1b</td>\n",
              "      <td>114.096877</td>\n",
              "      <td>109.441654</td>\n",
              "      <td>101.716981</td>\n",
              "      <td>36.235294</td>\n",
              "      <td>41.504065</td>\n",
              "      <td>114.883887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id     avg_red   avg_green    avg_blue      avg_h      avg_s       avg_v\n",
              "0  fi8zos  105.825954   95.935978   84.807401  18.997557  52.505151  105.987770\n",
              "1  fie2qx  116.319292  112.056747  103.298224  14.058189  43.652817  116.648814\n",
              "2  fidedo  167.300836  165.844258  167.075575  39.674466  20.069788  170.325628\n",
              "3  fipe1b  114.096877  109.441654  101.716981  36.235294  41.504065  114.883887"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktxbkHcmqqhA"
      },
      "source": [
        "Merge Image Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "q6wWbITYfqfu",
        "outputId": "c44cae0e-2972-4bb8-97bb-db5f0fe9fcfe"
      },
      "source": [
        "train_data=train_data.merge(train_image_features,on='id',how='left')\n",
        "print(train_data.shape)\n",
        "train_data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3264, 42)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ocr_text</th>\n",
              "      <th>ocr_no_of_words</th>\n",
              "      <th>ocr_text_len</th>\n",
              "      <th>ocr_preprocess</th>\n",
              "      <th>ocr_preprocess_no_of_words</th>\n",
              "      <th>ocr_preprocess_text_len</th>\n",
              "      <th>index</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>downs</th>\n",
              "      <th>is_nsfw</th>\n",
              "      <th>media</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>subscribers</th>\n",
              "      <th>thumbnail.height</th>\n",
              "      <th>thumbnail.thumbnail</th>\n",
              "      <th>thumbnail.width</th>\n",
              "      <th>title</th>\n",
              "      <th>ups</th>\n",
              "      <th>url</th>\n",
              "      <th>datetime_temp</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>ups_normed</th>\n",
              "      <th>dank_level</th>\n",
              "      <th>title_no_of_words</th>\n",
              "      <th>title_len</th>\n",
              "      <th>title_preprocess</th>\n",
              "      <th>title_preprocess_no_of_words</th>\n",
              "      <th>title_preprocess_text_len</th>\n",
              "      <th>path</th>\n",
              "      <th>text</th>\n",
              "      <th>area</th>\n",
              "      <th>com</th>\n",
              "      <th>neg</th>\n",
              "      <th>pos</th>\n",
              "      <th>neu</th>\n",
              "      <th>avg_red</th>\n",
              "      <th>avg_green</th>\n",
              "      <th>avg_blue</th>\n",
              "      <th>avg_h</th>\n",
              "      <th>avg_s</th>\n",
              "      <th>avg_v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fjn3gy</td>\n",
              "      <td>when acvedenalh bite their toungue The monster...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>bite monster become</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>28606.0</td>\n",
              "      <td>1.584374e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>https://i.redd.it/swm384fj32n41.jpg</td>\n",
              "      <td>r/memes</td>\n",
              "      <td>9552833.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>https://b.thumbs.redditmedia.com/C15Fr3fcu3dln...</td>\n",
              "      <td>140.0</td>\n",
              "      <td>Absolutely disgusting</td>\n",
              "      <td>975.0</td>\n",
              "      <td>/r/memes/comments/fjn3gy/absolutely_disgusting/</td>\n",
              "      <td>2020-03-16 10:51:43</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.020640e-04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>absolutely disgusting</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>/content/train/class_1/fjn3gy.jpg</td>\n",
              "      <td>absolutely disgusting bite monster become</td>\n",
              "      <td>19600.0</td>\n",
              "      <td>-0.5709</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.52</td>\n",
              "      <td>154.929228</td>\n",
              "      <td>137.958439</td>\n",
              "      <td>137.032199</td>\n",
              "      <td>42.276996</td>\n",
              "      <td>52.257750</td>\n",
              "      <td>155.450549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fjn514</td>\n",
              "      <td>42069 OUNLMATU PAHDOMORO 12 ;</td>\n",
              "      <td>5.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28575.0</td>\n",
              "      <td>1.584374e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>https://i.redd.it/4hdh24op32n41.jpg</td>\n",
              "      <td>r/memes</td>\n",
              "      <td>9552833.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>default</td>\n",
              "      <td>140.0</td>\n",
              "      <td>Words cannot describe how much happiness I hav...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>/r/memes/comments/fjn514/words_cannot_describe...</td>\n",
              "      <td>2020-03-16 10:54:27</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.187240e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>words can not describe how much happiness have...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>/content/train/class_0/fjn514.jpg</td>\n",
              "      <td>words can not describe how much happiness have...</td>\n",
              "      <td>14700.0</td>\n",
              "      <td>0.5574</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.69</td>\n",
              "      <td>174.331474</td>\n",
              "      <td>172.198407</td>\n",
              "      <td>169.971316</td>\n",
              "      <td>33.731953</td>\n",
              "      <td>30.351939</td>\n",
              "      <td>182.356801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fjnkyy</td>\n",
              "      <td>Extroverts in quarantine Me an extrovert that ...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>quarantine extrovert people quarantine</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>28242.0</td>\n",
              "      <td>1.584376e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>https://i.redd.it/qn2yvbgq82n41.jpg</td>\n",
              "      <td>r/memes</td>\n",
              "      <td>9552832.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>default</td>\n",
              "      <td>140.0</td>\n",
              "      <td>My first meme</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/r/memes/comments/fjnkyy/my_first_meme/</td>\n",
              "      <td>2020-03-16 11:20:50</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>my first</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>/content/train/class_0/fjnkyy.jpg</td>\n",
              "      <td>my first quarantine extrovert people quarantine</td>\n",
              "      <td>19600.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>86.817131</td>\n",
              "      <td>83.663894</td>\n",
              "      <td>79.729390</td>\n",
              "      <td>11.316440</td>\n",
              "      <td>19.647247</td>\n",
              "      <td>87.663379</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...       avg_v\n",
              "0  fjn3gy  ...  155.450549\n",
              "1  fjn514  ...  182.356801\n",
              "2  fjnkyy  ...   87.663379\n",
              "\n",
              "[3 rows x 42 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "320O1961pQyf",
        "outputId": "2fd9b63f-a01c-4c44-a0c8-98d29ddc330b"
      },
      "source": [
        "validation_data=validation_data.merge(validation_image_features,on='id',how='left')\n",
        "print(validation_data.shape)\n",
        "validation_data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1615, 42)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ocr_text</th>\n",
              "      <th>ocr_no_of_words</th>\n",
              "      <th>ocr_text_len</th>\n",
              "      <th>ocr_preprocess</th>\n",
              "      <th>ocr_preprocess_no_of_words</th>\n",
              "      <th>ocr_preprocess_text_len</th>\n",
              "      <th>index</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>downs</th>\n",
              "      <th>is_nsfw</th>\n",
              "      <th>media</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>subscribers</th>\n",
              "      <th>thumbnail.height</th>\n",
              "      <th>thumbnail.thumbnail</th>\n",
              "      <th>thumbnail.width</th>\n",
              "      <th>title</th>\n",
              "      <th>ups</th>\n",
              "      <th>url</th>\n",
              "      <th>datetime_temp</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>ups_normed</th>\n",
              "      <th>dank_level</th>\n",
              "      <th>title_no_of_words</th>\n",
              "      <th>title_len</th>\n",
              "      <th>title_preprocess</th>\n",
              "      <th>title_preprocess_no_of_words</th>\n",
              "      <th>title_preprocess_text_len</th>\n",
              "      <th>path</th>\n",
              "      <th>text</th>\n",
              "      <th>area</th>\n",
              "      <th>com</th>\n",
              "      <th>neg</th>\n",
              "      <th>pos</th>\n",
              "      <th>neu</th>\n",
              "      <th>avg_red</th>\n",
              "      <th>avg_green</th>\n",
              "      <th>avg_blue</th>\n",
              "      <th>avg_h</th>\n",
              "      <th>avg_s</th>\n",
              "      <th>avg_v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fjswbp</td>\n",
              "      <td>When 4TaFAIR isn't winning against normal name...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>not winning normal people made wrong feel</td>\n",
              "      <td>7.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>23658.0</td>\n",
              "      <td>1.584394e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>https://i.redd.it/sz73uulps3n41.png</td>\n",
              "      <td>r/memes</td>\n",
              "      <td>9552814.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>https://b.thumbs.redditmedia.com/sHy7W5wGxK69b...</td>\n",
              "      <td>140.0</td>\n",
              "      <td>You can put the sentence into google translate...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>/r/memes/comments/fjswbp/you_can_put_the_sente...</td>\n",
              "      <td>2020-03-16 16:34:35</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>you can put the sentence into google translate...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>/content/validation/class_0/fjswbp.jpg</td>\n",
              "      <td>you can put the sentence into google translate...</td>\n",
              "      <td>16520.0</td>\n",
              "      <td>-0.6784</td>\n",
              "      <td>0.254</td>\n",
              "      <td>0.056</td>\n",
              "      <td>0.690</td>\n",
              "      <td>133.694618</td>\n",
              "      <td>120.305931</td>\n",
              "      <td>120.087506</td>\n",
              "      <td>69.180509</td>\n",
              "      <td>98.402620</td>\n",
              "      <td>141.853861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fjriyh</td>\n",
              "      <td>Me when everything was closed this weekend: ma...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>everything closed weekend made</td>\n",
              "      <td>4.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>24845.0</td>\n",
              "      <td>1.584390e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>https://i.redd.it/qb77i890e3n41.jpg</td>\n",
              "      <td>r/memes</td>\n",
              "      <td>9552816.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>https://b.thumbs.redditmedia.com/z0JhDTea1T_uF...</td>\n",
              "      <td>140.0</td>\n",
              "      <td>*Sad me noises*</td>\n",
              "      <td>23.0</td>\n",
              "      <td>/r/memes/comments/fjriyh/sad_me_noises/</td>\n",
              "      <td>2020-03-16 15:12:10</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>sad me noises</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>/content/validation/class_0/fjriyh.jpg</td>\n",
              "      <td>sad me noises everything closed weekend made</td>\n",
              "      <td>19600.0</td>\n",
              "      <td>-0.4767</td>\n",
              "      <td>0.341</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.659</td>\n",
              "      <td>144.465904</td>\n",
              "      <td>148.956254</td>\n",
              "      <td>140.275021</td>\n",
              "      <td>58.527916</td>\n",
              "      <td>60.928690</td>\n",
              "      <td>158.697454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fjrfvn</td>\n",
              "      <td>Roses are red, get boned by the pastor; The ch...</td>\n",
              "      <td>19.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>red get boned pastor fast combine faster</td>\n",
              "      <td>7.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>24912.0</td>\n",
              "      <td>1.584389e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>https://i.redd.it/udybjadsc3n41.png</td>\n",
              "      <td>r/memes</td>\n",
              "      <td>9552816.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>default</td>\n",
              "      <td>140.0</td>\n",
              "      <td>Gotta go speed</td>\n",
              "      <td>2045.0</td>\n",
              "      <td>/r/memes/comments/fjrfvn/gotta_go_speed/</td>\n",
              "      <td>2020-03-16 15:06:59</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>gotta go speed</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>/content/validation/class_1/fjrfvn.jpg</td>\n",
              "      <td>gotta go speed red get boned pastor fast combi...</td>\n",
              "      <td>19600.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>186.236102</td>\n",
              "      <td>171.321177</td>\n",
              "      <td>150.937902</td>\n",
              "      <td>27.600595</td>\n",
              "      <td>78.040035</td>\n",
              "      <td>190.878357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...       avg_v\n",
              "0  fjswbp  ...  141.853861\n",
              "1  fjriyh  ...  158.697454\n",
              "2  fjrfvn  ...  190.878357\n",
              "\n",
              "[3 rows x 42 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymnG-NLlgvfc"
      },
      "source": [
        "train_data['hour']=train_data['datetime_temp'].apply(lambda x:int(x[11:13]))\n",
        "validation_data['hour']=validation_data['datetime_temp'].apply(lambda x:int(x[11:13]))\n",
        "test_data['hour']=test_data['datetime_temp'].apply(lambda x:int(x[11:13]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySH2rD4mfsVs"
      },
      "source": [
        "#numeric features for training\n",
        "list_features=['ocr_no_of_words', 'ocr_text_len', 'ocr_preprocess_no_of_words', 'ocr_preprocess_text_len',\n",
        "               'title_no_of_words', 'title_len','title_preprocess_no_of_words', 'title_preprocess_text_len',\n",
        "              'thumbnail.height' , 'thumbnail.width','time_of_day','hour','area','com', 'neg', 'pos', 'neu',\n",
        "               'avg_red','avg_green','avg_blue','avg_h','avg_s','avg_v']\n",
        "\n",
        "def min_max_scaling(df,list_features,dict_mm={ }):\n",
        "    \n",
        "    result = df.copy()\n",
        "    if not bool(dict_mm):  #if dict is empty then we are finding mean and max for train data\n",
        "        for feature_name in list_features:\n",
        "            max_value = df[feature_name].max()\n",
        "            min_value = df[feature_name].min()\n",
        "            dict_mm[feature_name]=[max_value,min_value]\n",
        "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "        return result,dict_mm   \n",
        "    else:                    #use train data min and max\n",
        "        for feature_name in list_features:\n",
        "            max_value=dict_mm[feature_name][0]\n",
        "            min_value=dict_mm[feature_name][1]\n",
        "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "        return result\n",
        "\n",
        "# min-max scaling on numeric features\n",
        "train_data,dict_mm=min_max_scaling(train_data,list_features)\n",
        "validation_data=min_max_scaling(validation_data,list_features,dict_mm)\n",
        "\n",
        "train_numeric=train_data[list_features]\n",
        "validation_numeric=validation_data[list_features]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFjdOEfArrBm",
        "outputId": "84fac94d-03f5-4824-9e50-558cb0df68a2"
      },
      "source": [
        "vectorizer1=TfidfVectorizer(min_df=2,ngram_range=(1,4))\n",
        "vectorizer1.fit(train_data['text'].values)\n",
        "\n",
        "train_data_text_tfidf = vectorizer1.transform(train_data['text'].values)\n",
        "validation_data_text_tfidf = vectorizer1.transform(validation_data['text'].values)\n",
        "test_data_text_tfidf  = vectorizer1.transform(test_data['text'].values)\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(train_data_text_tfidf.shape)\n",
        "print(validation_data_text_tfidf.shape)\n",
        "print(test_data_text_tfidf.shape)\n",
        "print(\"=\"*100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After vectorizations\n",
            "(3264, 7835)\n",
            "(1615, 7835)\n",
            "(1637, 7835)\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFZfq88dr9LR"
      },
      "source": [
        "dictionary = dict(zip(vectorizer1.get_feature_names(), list(vectorizer1.idf_)))\n",
        "tfidf_words = set(vectorizer1.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoaawC_jr9Ii"
      },
      "source": [
        "with open('glove_vectors', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "    glove_words =  set(model.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-UdDS8_r9Fn",
        "outputId": "2db98874-d413-4186-ac1d-e7d624aa0c6d"
      },
      "source": [
        "# reference appliedai\n",
        "# average Word2Vec\n",
        "# compute average word2vec for each review.\n",
        "tfidf_w2v_vectors_train = []; # the avg-w2v for each sentence/review is stored in this list\n",
        "for sentence in tqdm(train_data['text'].values): # for each review/sentence\n",
        "    vector = np.zeros(300) # as word vectors are of zero length\n",
        "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
        "    for word in sentence.split(): # for each word in a review/sentence\n",
        "        if (word in glove_words) and (word in tfidf_words):\n",
        "            vec = model[word] # getting the vector for each word\n",
        "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
        "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
        "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
        "            tf_idf_weight += tf_idf\n",
        "    if tf_idf_weight != 0:\n",
        "        vector /= tf_idf_weight\n",
        "    tfidf_w2v_vectors_train.append(vector)\n",
        "\n",
        "print(len(tfidf_w2v_vectors_train))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3264/3264 [00:00<00:00, 12815.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPTJBKO1r9Cr",
        "outputId": "8f2f5ff3-4325-434e-ccc5-4a0724606c01"
      },
      "source": [
        "# average Word2Vec\n",
        "# compute average word2vec for each review.\n",
        "tfidf_w2v_vectors_validation = []; # the avg-w2v for each sentence/review is stored in this list\n",
        "for sentence in tqdm(validation_data['text'].values): # for each review/sentence\n",
        "    vector = np.zeros(300) # as word vectors are of zero length\n",
        "    tf_idf_weight =0; # num of words with a valid vector in the sentence/review\n",
        "    for word in sentence.split(): # for each word in a review/sentence\n",
        "        if (word in glove_words) and (word in tfidf_words):\n",
        "            vec = model[word] # getting the vector for each word\n",
        "            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)/len(sentence.split())))\n",
        "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split())) # getting the tfidf value for each word\n",
        "            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n",
        "            tf_idf_weight += tf_idf\n",
        "    if tf_idf_weight != 0:\n",
        "        vector /= tf_idf_weight\n",
        "    tfidf_w2v_vectors_validation.append(vector)\n",
        "\n",
        "print(len(tfidf_w2v_vectors_validation))\n",
        "len(tfidf_w2v_vectors_validation[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1615/1615 [00:00<00:00, 8654.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah45EiQWsnkI"
      },
      "source": [
        "train_numeric=scipy.sparse.csr_matrix(train_numeric)\n",
        "validation_numeric=scipy.sparse.csr_matrix(validation_numeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqDngh-Xsng4",
        "outputId": "a6c4e90d-3917-43f0-b128-36c43d70cf78"
      },
      "source": [
        "# merge two sparse matrices: https://stackoverflow.com/a/19710648/4084039\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "X_train = hstack((tfidf_w2v_vectors_train,   train_numeric)).tocsr()\n",
        "X_validation = hstack((tfidf_w2v_vectors_validation, validation_numeric)).tocsr()\n",
        "\n",
        "print(\"Final Data matrix\")\n",
        "print(X_train.shape)\n",
        "print(X_validation.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Data matrix\n",
            "(3264, 323)\n",
            "(1615, 323)\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWUzCljRsnd4",
        "outputId": "a7efca36-1456-4bb1-a331-8a733064c575"
      },
      "source": [
        "X_train = hstack((tfidf_w2v_vectors_train, train_numeric)).tocsr()\n",
        "X_validation = hstack((tfidf_w2v_vectors_validation, validation_numeric)).tocsr()\n",
        "\n",
        "print(\"Final Data matrix\")\n",
        "print(X_train.shape)\n",
        "print(X_validation.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Data matrix\n",
            "(3264, 323)\n",
            "(1615, 323)\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3o4Z3hYs4JX",
        "outputId": "e4c1e7eb-a82e-4a8a-c07e-5c4b56d6d001"
      },
      "source": [
        "xgbc = XGBClassifier()\n",
        "parameters = {'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3] ,\n",
        "              'n_estimators':range(5,100),\n",
        "              'colsample_bytree':[0.2,0.25,0.3]}\n",
        "clf =  RandomizedSearchCV(xgbc, parameters, cv=3, scoring='roc_auc',return_train_score=True,n_jobs=-1)\n",
        "clf.fit(X_train, train_data['dank_level'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                           colsample_bylevel=1,\n",
              "                                           colsample_bynode=1,\n",
              "                                           colsample_bytree=1, gamma=0,\n",
              "                                           learning_rate=0.1, max_delta_step=0,\n",
              "                                           max_depth=3, min_child_weight=1,\n",
              "                                           missing=None, n_estimators=100,\n",
              "                                           n_jobs=1, nthread=None,\n",
              "                                           objective='binary:logistic',\n",
              "                                           random_state=0, reg_alpha=0,\n",
              "                                           reg_lambda=1, scale_pos_weight=1,\n",
              "                                           seed=None, silent=None, subsample=1,\n",
              "                                           verbosity=1),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'colsample_bytree': [0.2, 0.25, 0.3],\n",
              "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
              "                                                          0.1, 0.2, 0.3],\n",
              "                                        'n_estimators': range(5, 100)},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=True, scoring='roc_auc', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "jcQlV1XVs7Ba",
        "outputId": "3f54d424-676b-4e35-bcb0-1db8b485ebb6"
      },
      "source": [
        "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
        "results[['mean_train_score','mean_test_score', 'param_learning_rate','param_n_estimators','param_colsample_bytree']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_colsample_bytree</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.773172</td>\n",
              "      <td>0.605066</td>\n",
              "      <td>0.001</td>\n",
              "      <td>93</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.950858</td>\n",
              "      <td>0.605500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>86</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.738004</td>\n",
              "      <td>0.594600</td>\n",
              "      <td>0.001</td>\n",
              "      <td>16</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.777668</td>\n",
              "      <td>0.597261</td>\n",
              "      <td>0.01</td>\n",
              "      <td>22</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.744495</td>\n",
              "      <td>0.595900</td>\n",
              "      <td>0.01</td>\n",
              "      <td>14</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.778040</td>\n",
              "      <td>0.607070</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>51</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.755468</td>\n",
              "      <td>0.602983</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>74</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.810391</td>\n",
              "      <td>0.597434</td>\n",
              "      <td>0.1</td>\n",
              "      <td>15</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.780161</td>\n",
              "      <td>0.582497</td>\n",
              "      <td>0.3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.756207</td>\n",
              "      <td>0.602234</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>86</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_score  mean_test_score  ... param_n_estimators param_colsample_bytree\n",
              "0          0.773172         0.605066  ...                 93                   0.25\n",
              "1          0.950858         0.605500  ...                 86                    0.2\n",
              "2          0.738004         0.594600  ...                 16                    0.3\n",
              "3          0.777668         0.597261  ...                 22                    0.2\n",
              "4          0.744495         0.595900  ...                 14                    0.3\n",
              "5          0.778040         0.607070  ...                 51                    0.2\n",
              "6          0.755468         0.602983  ...                 74                    0.3\n",
              "7          0.810391         0.597434  ...                 15                   0.25\n",
              "8          0.780161         0.582497  ...                  7                   0.25\n",
              "9          0.756207         0.602234  ...                 86                    0.3\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Il_ku5yiSv"
      },
      "source": [
        "Train xgboost on learning_rate=0.0001 ,n_estimator=74,colsample_bytree=0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgAggYYxs9ks",
        "outputId": "e7dca8df-0456-4026-e25e-609b68213d65"
      },
      "source": [
        "xgbc_final = XGBClassifier( learning_rate=0.0001 ,n_estimator=74,colsample_bytree=0.3)\n",
        "xgbc_final.fit(X_train, train_data['dank_level'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=0.3, gamma=0,\n",
              "              learning_rate=0.0001, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimator=74,\n",
              "              n_estimators=100, n_jobs=1, nthread=None,\n",
              "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
              "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
              "              subsample=1, verbosity=1)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvlImzY6zK17",
        "outputId": "653be575-b226-4801-a768-423fed0f7cb2"
      },
      "source": [
        "train_prediction=xgbc_final.predict_proba(X_train)\n",
        "print('train auc is=',roc_auc_score(np.array(train_data['dank_level']), train_prediction[:,1]))\n",
        "validation_prediction=xgbc_final.predict_proba(X_validation)\n",
        "print('validation auc is=',roc_auc_score(np.array(validation_data['dank_level']), validation_prediction[:,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train auc is= 0.7177683668870192\n",
            "validation auc is= 0.6216693517453011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U8_qMsq0w1l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}