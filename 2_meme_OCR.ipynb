{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meme_OCR",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2mZC3cHzW3m"
      },
      "source": [
        "!wget --header=\"Host: doc-0o-0g-drive-data-export.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Cookie: AUTH_q9gllbu0nte95409rtp7q7s721mapf6v_nonce=vvim2copfnj4s\" --header=\"Connection: keep-alive\" \"https://doc-0o-0g-drive-data-export.googleusercontent.com/download/b3n3f7ro91h5cr0rs39bilh5evv17sjb/768o5famgcgilpb6ac4qrt7scien22aj/1622371500000/5f250682-e6b5-4aab-827b-d896868e70dd/110819034128027560352/ADt3v-NxvzdHPn5Euk9c55oh3sWYpvKYmiz7B35xq5Vy82W1Z0HJ7U65UVPkDPhHQlCmiZcStHu-a5rbs01f59lF7sKTSTygXm6wdG57GTE8Y1AvemIZA2yQ9v0-k-shLui4w38Y2LxiK2b5KjEIfRKnes3HZ9UdxQQq8byqxQk52UAi7x_QR1gkn1Q_P1qHRyQ9-SDGf3GuCThgZFqApbJLm1EV4FAKw4YOZ4emfc454OMTsriV77CeKMCLw0jBLxFyNN42jR6nlUCbc1kdPaWKiyGV7L0WvJG674eiDORMMRabYJDkrhKJU4eGjCwd3WZqLu8nxG8Z?authuser=0&nonce=vvim2copfnj4s&user=110819034128027560352&hash=cqno48rsdfe6ilopvofn67rggi4vql4d\" -c -O 'train-20210530T104616Z-001.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IzOas-UKF_S"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUKKD6Id7EdT"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import easyocr\n",
        "import os\n",
        "import pickle\n",
        "import shutil\n",
        "import re\n",
        "import warnings\n",
        "from zipfile import ZipFile\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7RqQ-Ha2KHc",
        "outputId": "d145323f-25b9-4910-b7aa-859100ad60a0"
      },
      "source": [
        "import nltk \n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88S0S5pUBWY_",
        "outputId": "647bc89b-537e-42d7-f0e4-33bc62ddc224"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = set(nltk.corpus.stopwords.words('english')) \n",
        "stopwords.remove('not')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bIm1V0n7LwQ",
        "outputId": "6e2fd152-981a-4f0a-cc1e-e62c4720417d"
      },
      "source": [
        "#load model for english language\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLtQnw-c6mFB"
      },
      "source": [
        "# Read text from all images with OCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aVolFTl7jcB"
      },
      "source": [
        "def give_text_from_images(raw_path):# read text from images\n",
        "    exception_data=[]\n",
        "    dict_data={}                 # this dictionary contain image_name and text given by ocr\n",
        "    root=os.listdir(raw_path)    #list all images in folder\n",
        "    for image_name in root:\n",
        "      path=raw_path+image_name\n",
        "      try:\n",
        "        output = reader.readtext(path)     # readtext method read text in images\n",
        "        ocr_text=' '\n",
        "        for i in output:      # output[0]=cordinates of text,output[1]=text ,output[2]=probability\n",
        "          if i[2]>=0.25:       # select text which has probability greater than 0.25\n",
        "            ocr_text+=i[1]+\" \"\n",
        "        dict_data[image_name] =ocr_text\n",
        "      except:                  # if images is not png, jpg in that case ignore it\n",
        "        exception_data.append(image_name)\n",
        "    return dict_data,exception_data    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHmn_jmGGn3U"
      },
      "source": [
        "# reading text from train folder images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjrwXBfN_D4-"
      },
      "source": [
        "# reading text from train folder\n",
        "train_text,train_exception=give_text_from_images('/content/drive/MyDrive/Meme/data/train/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UsChdwZJoW9",
        "outputId": "1dc8c49a-83d0-4cf2-b94a-08086905da4a"
      },
      "source": [
        "# these images are in gif format  so I have removed these\n",
        "train_exception"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fifxei.jpg',\n",
              " 'fivqpe.jpg',\n",
              " 'fminyf.jpg',\n",
              " 'fn2aeh.jpg',\n",
              " 'fk1zqf.jpg',\n",
              " 'flzxlu.jpg',\n",
              " 'fm0153.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhBImqcWDQM-"
      },
      "source": [
        "# save train_text in pickle file\n",
        "pickle.dump(train_text, open(\"/content/drive/MyDrive/Meme/data/train_text\", \"wb\"))\n",
        "pickle.dump(train_exception, open(\"/content/drive/MyDrive/Meme/data/train_exception\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jx5yxYWGpq7"
      },
      "source": [
        "# reading text from validation folder images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uBWCmxiAnUv"
      },
      "source": [
        "validation_text,validation_exception=give_text_from_images('/content/drive/MyDrive/Meme/data/validation/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kH5B9jj9ok8",
        "outputId": "1dcb5d1c-dda5-4124-fc65-1b57cb2b4ccd"
      },
      "source": [
        "#these images are in gif format  so I have removed these\n",
        "validation_exception"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fkm56e.jpg', 'fkp4hr.jpg', 'flq4z6.jpg', 'fiawku.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMj_rn-LDKIs"
      },
      "source": [
        "#save validation_text in pickle file\n",
        "pickle.dump(validation_text, open(\"/content/drive/MyDrive/Meme/data/validation_text\", \"wb\"))\n",
        "pickle.dump(validation_exception, open(\"/content/drive/MyDrive/Meme/data/validation_exception\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWqFNA5SGyO1"
      },
      "source": [
        "# reading text from test folder images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCVAFcn4DsfI"
      },
      "source": [
        "test_text,test_exception=give_text_from_images('/content/drive/MyDrive/Meme/data/test/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjDvTMVKOJeV"
      },
      "source": [
        "#save test_text in pickle file\n",
        "pickle.dump(test_text, open(\"/content/drive/MyDrive/Meme/data/test_text\", \"wb\"))\n",
        "pickle.dump(test_exception, open(\"/content/drive/MyDrive/Meme/data/test_exception\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKdXvz51G2an",
        "outputId": "3329c48c-6918-47fd-bf35-4967fda103ff"
      },
      "source": [
        "#these images are in gif format  so I have removed these\n",
        "test_exception"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fn7b6i.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGInqbyLnldf"
      },
      "source": [
        "# seperate dank and not dank meme"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWIl0yxZkkiW"
      },
      "source": [
        "def fun(source,destination,data):\n",
        "    # before this function create folder class_0 and class_1\n",
        "    # for every class that we have in our  directory we check if it's dank_level=1 then we will move it in class_1\n",
        "    # otherwise move in class_0\n",
        "    # list_id for dank_level==1\n",
        "    list_id=list(data[data.dank_level==1]['id'])\n",
        "    if os.path.isdir(source):\n",
        "        data_files = os.listdir(source)\n",
        "        for file in data_files:\n",
        "            file_temp=file.split(\".\")[0]\n",
        "            if file_temp in list_id:\n",
        "              #if dank_level=1 then we remove in class_1\n",
        "              shutil.move(source+'/'+file,destination+'/class_1') \n",
        "            else:\n",
        "              if file!=='class_1':\n",
        "                shutil.move(source+'/'+file,destination+'/class_0')   \n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg-41Wigoham"
      },
      "source": [
        "#reading csv file of data\n",
        "data=pd.read_csv('/content/drive/MyDrive/Meme/data/data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDfyYtVY-dBs"
      },
      "source": [
        "#separating class 1 and 0\n",
        "source_train = '/content/drive/MyDrive/Meme/data/train'\n",
        "destination_train= '/content/drive/MyDrive/Meme/data/train'\n",
        "# call function  to seperate class 1 and 0\n",
        "fun(source_train,destination_train,data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWIdAfaqCrZs"
      },
      "source": [
        "source_validation = '/content/drive/MyDrive/Meme/data/validation'\n",
        "destination_validation='/content/drive/MyDrive/Meme/data/validation'\n",
        "#call function to seperate class 1 and 0\n",
        "fun(source_validation,destination_validation,data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfF6f8FuS8h2"
      },
      "source": [
        "# read saved ocr text from train and validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C97wRsIhUnCc"
      },
      "source": [
        "train_text=pickle.load(open('/content/drive/MyDrive/Meme/data/train_text','rb'))\n",
        "validation_text=pickle.load(open('/content/drive/MyDrive/Meme/data/validation_text','rb'))\n",
        "test_text=pickle.load(open(\"/content/drive/MyDrive/Meme/data/test_text\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZDFiy6RwXbe"
      },
      "source": [
        "train_text=pd.DataFrame(train_text.items(), columns=['id','ocr_text'])\n",
        "validation_text=pd.DataFrame(validation_text.items(), columns=['id','ocr_text'])\n",
        "test_text=pd.DataFrame(test_text.items(), columns=['id','ocr_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2TWq1f6SrTl"
      },
      "source": [
        "# steps for ocr text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q89GhO5NhFh1"
      },
      "source": [
        "1. convert lower case\n",
        "2. correct some cases  like this Don\\'t,dont,dontt\n",
        "2. remove some puctuation\n",
        "3. remove word starts with @ and mem , words length<1 and words which are not  in english dictionary and stopwords\n",
        "4. remove all non-words "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_1HDEvMA0Xk"
      },
      "source": [
        "#some text features are\n",
        "1. length of characters in ocr_text and no of words in ocr_text\n",
        "2.length of characters in ocr_preprocess_text and no of words in ocr_preprocess_text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19zM_MXBGXR7"
      },
      "source": [
        "def ocr_preprocess(text_data):\n",
        "  for i,row in text_data.iterrows():\n",
        "      value=row['ocr_text']\n",
        "      value=value.strip()  #remove space at begining and ending\n",
        "      text_data.loc[i,'ocr_text']=value   #from orignal text remove space\n",
        "      value=value.lower()\n",
        "      text_data.loc[i,'ocr_no_of_words']=len(value.split())    # count no_of_words before preprocessing \n",
        "      text_data.loc[i,'ocr_text_len']=len(value)                  #len of text\n",
        "      \n",
        "      # to handle  cases like this Don\\'t,dont,dontt\n",
        "      # replace Don\\'t with do not use replace(\"n't\", \" not\")\n",
        "      # reference appliedai.com\n",
        "      value=value.replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
        "                            .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
        "                            .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
        "                            .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'ll\", \" will\")\\\n",
        "                            .replace(\"'s\", \" is\").replace(\"'ll\", \" will\").replace(\"'m\", \" am\")\\\n",
        "                            .replace(\"'t\", \" not\").replace(\"'d\", \" would\").replace(\"dont\",\"do not \").replace(\"dont\",\"do not\")\\\n",
        "                            .replace(\"dontt\",\"do not\")\n",
        "      # remove  \\n,\\t,(,),|,.,-,_,<,>,?,!,\\,:,;,{,},*,#,%,\n",
        "      value=re.sub(r'[\\n\\t()|.-_<>,?!\\\\:;{}*#%]+',' ', value)   \n",
        "      # remove  word start with mem \n",
        "      # remove  word  start with @   like  @steve \n",
        "      # word less than len 1\n",
        "      x=' '.join(x for x in value.split()  if   not x.startswith('@') and not x.startswith('mem') and  x in words and len(x)>1 and x not in stopwords )\n",
        "      #remove puctuation from words  /,[,],_ like r/Minecraft,[BIDET,closeraoa_,ulone_slavic_boy, u/TheOriginalNav \n",
        "      #remove all digit\n",
        "      x=re.sub(\"\\W\",\" \",x)\n",
        "      x=x.strip()\n",
        "      text_data.loc[i,'ocr_preprocess']=x  \n",
        "      text_data.loc[i,'ocr_preprocess_no_of_words']=len(x.split())\n",
        "      text_data.loc[i,'ocr_preprocess_text_len']=len(x)\n",
        "  return text_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAtbHxBvSv_6"
      },
      "source": [
        "#call preprocess function\n",
        "validation_text=ocr_preprocess(validation_text)\n",
        "train_text=ocr_preprocess(train_text)\n",
        "test_text=ocr_preprocess(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isi-BzYG9wTn",
        "outputId": "2b7623de-cf34-42e2-a993-581ef501be5b"
      },
      "source": [
        "train_text.shape,validation_text.shape,test_text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3264, 7), (1852, 7), (1637, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gfU2lbLMbHh"
      },
      "source": [
        "#seperate csv file for traing and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHwkU1b5xy6U",
        "outputId": "8e4d640b-9014-4ae6-f3c7-cfab545d75c8"
      },
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Meme/data/data.csv')\n",
        "#drop duplicates from data\n",
        "data=data.drop_duplicates(subset=['id'],keep='first').reset_index(drop=True)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67244, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0BjtHT_0MYd"
      },
      "source": [
        "train_text['id']=train_text['id'].apply(lambda x:x.split('.')[0])\n",
        "train_data=train_text.merge(data,on='id',how='inner')\n",
        "train_data=train_data.drop_duplicates(subset=['id'],keep='first').reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgmXOA9M0A9f"
      },
      "source": [
        "validation_text['id']=validation_text['id'].apply(lambda x:x.split('.')[0])\n",
        "validation_data=validation_text.merge(data,on='id',how='inner')\n",
        "validation_data=validation_data.drop_duplicates(subset=['id'],keep='first').reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjNcuAVGahK5"
      },
      "source": [
        "test_text['id']=test_text['id'].apply(lambda x:x.split('.')[0])\n",
        "test_data=test_text.merge(data,on='id',how='inner')\n",
        "test_data=test_data.drop_duplicates(subset=['id'],keep='first').reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR_14X3ZHpWu",
        "outputId": "9486e949-c71c-4253-9271-91524d2dba43"
      },
      "source": [
        "train_data.shape,validation_data.shape,test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3264, 24), (1615, 24), (1637, 24))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2gHexlXE6IC"
      },
      "source": [
        "def title_preprocess(text_data):\n",
        "  for i,row in text_data.iterrows():\n",
        "      value=row['title']\n",
        "      value=value.strip()  #remove space at begining and ending\n",
        "      text_data.loc[i,'title']=value   #from orignal text remove space\n",
        "      value=value.lower()\n",
        "      text_data.loc[i,'title_no_of_words']=len(value.split())    # count no_of_words before preprocessing \n",
        "      text_data.loc[i,'title_len']=len(value)                  #len of text\n",
        "      \n",
        "      # to handle  cases like this Don\\'t,dont,dontt\n",
        "      # replace Don\\'t with do not use replace(\"n't\", \" not\")\n",
        "      # reference appliedai.com\n",
        "      value=value.replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
        "                            .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
        "                            .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
        "                            .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'ll\", \" will\")\\\n",
        "                            .replace(\"'s\", \" is\").replace(\"'ll\", \" will\").replace(\"'m\", \" am\")\\\n",
        "                            .replace(\"'t\", \" not\").replace(\"'d\", \" would\").replace(\"dont\",\"do not \").replace(\"dont\",\"do not\")\\\n",
        "                            .replace(\"dontt\",\"do not\").replace(\"me_irl\",\"me irl\").replace(\"Me_irl\",'me irl')\n",
        "      # remove  \\n,\\t,(,),|,.,-,_,<,>,?,!,\\,:,;,{,},*,#,%,\n",
        "      value=re.sub(r'[\\n\\t()|.-_<>,?!\\\\:;{}*#%]+',' ', value)   \n",
        "      # remove  word start with mem \n",
        "      # remove  word  start with @   like  @steve \n",
        "      # word less than len 1\n",
        "      x=' '.join(x for x in value.split()  if   not x.startswith('@') and not x.startswith('mem') and len(x)>1 )\n",
        "      #remove puctuation from words  /,[,],_ like r/Minecraft,[BIDET,closeraoa_,ulone_slavic_boy, u/TheOriginalNav \n",
        "      #remove all digit\n",
        "      x=re.sub(\"\\W\",\" \",x)\n",
        "      x=x.strip()\n",
        "      text_data.loc[i,'title_preprocess']=x  \n",
        "      text_data.loc[i,'title_preprocess_no_of_words']=len(x.split())\n",
        "      text_data.loc[i,'title_preprocess_text_len']=len(x)\n",
        "  return text_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDmN0l-eHVvx"
      },
      "source": [
        "validation_data=title_preprocess(validation_data)\n",
        "train_data=title_preprocess(train_data)\n",
        "test_data=title_preprocess(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m8tDyAq5XVG"
      },
      "source": [
        "#add_path of each images in csv file\n",
        "def add_path(temp,data):\n",
        "    for i,row in data.iterrows():\n",
        "      root='/content/'+temp+'/'   #/content/validation/\n",
        "      if row['dank_level']==1:\n",
        "        data.loc[i,'path']=root+'class_1/'+row['id']+'.jpg'\n",
        "      elif row['dank_level']==0:\n",
        "        data.loc[i,'path']=root+'class_0/'+row['id']+'.jpg'\n",
        "      else: \n",
        "        data.loc[i,'path'] ='error'  \n",
        "    return data\n",
        "train_data=add_path('train',train_data)\n",
        "validation_data=add_path('validation',validation_data)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE_5zpIubSey"
      },
      "source": [
        "def test_data_path(data):\n",
        "    for i,row in data.iterrows():\n",
        "      root='/content/test/'\n",
        "      data.loc[i,'path']=root+row['id']+'.jpg'\n",
        "    return data\n",
        "test_data=test_data_path(test_data)      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qmmec_pNXe2"
      },
      "source": [
        "train_data['text']= train_data['title_preprocess'].astype(str)+\" \"+train_data['ocr_preprocess'].astype(str)\n",
        "validation_data['text']=validation_data['title_preprocess'].astype(str)+\" \"+validation_data['ocr_preprocess'].astype(str)\n",
        "test_data['text']=test_data['title_preprocess'].astype(str)+' '+test_data['ocr_preprocess'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "5YCEMVLFO9d_",
        "outputId": "bb5d13a9-2f5a-4ee9-9e02-2019cb18da05"
      },
      "source": [
        "train_data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ocr_text</th>\n",
              "      <th>ocr_no_of_words</th>\n",
              "      <th>ocr_text_len</th>\n",
              "      <th>ocr_preprocess</th>\n",
              "      <th>ocr_preprocess_no_of_words</th>\n",
              "      <th>ocr_preprocess_text_len</th>\n",
              "      <th>index</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>downs</th>\n",
              "      <th>is_nsfw</th>\n",
              "      <th>media</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>subscribers</th>\n",
              "      <th>thumbnail.height</th>\n",
              "      <th>thumbnail.thumbnail</th>\n",
              "      <th>thumbnail.width</th>\n",
              "      <th>title</th>\n",
              "      <th>ups</th>\n",
              "      <th>url</th>\n",
              "      <th>datetime_temp</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>ups_normed</th>\n",
              "      <th>dank_level</th>\n",
              "      <th>title_no_of_words</th>\n",
              "      <th>title_len</th>\n",
              "      <th>title_preprocess</th>\n",
              "      <th>title_preprocess_no_of_words</th>\n",
              "      <th>title_preprocess_text_len</th>\n",
              "      <th>path</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fjn3gy</td>\n",
              "      <td>when acvedenalh bite their toungue The monster...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>bite monster become</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>28606.0</td>\n",
              "      <td>1.584374e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>https://i.redd.it/swm384fj32n41.jpg</td>\n",
              "      <td>r/memes</td>\n",
              "      <td>9552833.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>https://b.thumbs.redditmedia.com/C15Fr3fcu3dln...</td>\n",
              "      <td>140.0</td>\n",
              "      <td>Absolutely disgusting</td>\n",
              "      <td>975.0</td>\n",
              "      <td>/r/memes/comments/fjn3gy/absolutely_disgusting/</td>\n",
              "      <td>2020-03-16 10:51:43</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.020640e-04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>absolutely disgusting</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>/content/train/class_1/fjn3gy.jpg</td>\n",
              "      <td>absolutely disgusting bite monster become</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fjn514</td>\n",
              "      <td>42069 OUNLMATU PAHDOMORO 12 ;</td>\n",
              "      <td>5.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28575.0</td>\n",
              "      <td>1.584374e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>https://i.redd.it/4hdh24op32n41.jpg</td>\n",
              "      <td>r/memes</td>\n",
              "      <td>9552833.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>default</td>\n",
              "      <td>140.0</td>\n",
              "      <td>Words cannot describe how much happiness I hav...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>/r/memes/comments/fjn514/words_cannot_describe...</td>\n",
              "      <td>2020-03-16 10:54:27</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.187240e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>words can not describe how much happiness have...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>/content/train/class_0/fjn514.jpg</td>\n",
              "      <td>words can not describe how much happiness have...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...                                               text\n",
              "0  fjn3gy  ...          absolutely disgusting bite monster become\n",
              "1  fjn514  ...  words can not describe how much happiness have...\n",
              "\n",
              "[2 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx1CivGv0Az1"
      },
      "source": [
        "#save train_data and validation_data\n",
        "train_data.to_csv('/content/drive/MyDrive/Meme/data/train_data.csv',index=False)\n",
        "validation_data.to_csv('/content/drive/MyDrive/Meme/data/validation_data.csv',index=False)\n",
        "test_data.to_csv('/content/drive/MyDrive/Meme/data/test_data.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDS_xqeCMxoX",
        "outputId": "261cbbb4-3c7b-4f83-d9f8-ac6807daf530"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(validation_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3264, 31)\n",
            "(1615, 31)\n",
            "(1637, 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "belH9USN3etQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}